{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Tue Nov 29 10:03:12 2022"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@author: chandu\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Chronic Kidney Disease Prediction <br>\n", " Using PCA for Dimension Reduction & Random forest Classifier for Predicting "]}, {"cell_type": "markdown", "metadata": {}, "source": ["# importing required libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from sklearn.decomposition import PCA\n", "import matplotlib.pyplot as plt\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(r'C:\\Users\\chandu\\Desktop\\Course\\Data Science\\Machine_Learning_Practice\\3_PCA\\Chronic_Kidney_Disease\\kidney_disease.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Data is Semi-Structured, Offline, Cross Sectional and Regular Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()\n", "df.columns"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Checking whether the Data is Balanced vs Imbalanced <br>\n", " y is ckd/no-ckd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['classification'].value_counts() ### Data is Imbalanced "]}, {"cell_type": "markdown", "metadata": {}, "source": [" Dropping ID Column which is not relavent"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.drop('id', axis = 1, inplace = True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Data Preprocessing stage"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Typecasting"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.info() "]}, {"cell_type": "markdown", "metadata": {}, "source": [" pcv,wc,rc are numerical datapoints but they are read as object type so typecasting for them"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['pcv'] = pd.to_numeric(df['pcv'], errors = 'coerce')\n", "df['wc'] = pd.to_numeric(df['wc'], errors = 'coerce')\n", "df['rc'] = pd.to_numeric(df['rc'], errors = 'coerce')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Checking for Duplicates"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.duplicated().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Checking for Missing values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.isna().sum() "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['age'] = df['age'].fillna(df['age'].median())\n", "df['bp'] = df['bp'].fillna(df['bp'].median())\n", "df['sg'] = df['sg'].fillna(df['sg'].median())\n", "df['al'] = df['al'].fillna(df['al'].median())\n", "df['su'] = df['su'].fillna(df['su'].mode()[0])\n", "df['rbc'] = df['rbc'].fillna(df['rbc'].mode()[0])\n", "df['pc'] = df['pc'].fillna(df['pc'].mode()[0])\n", "df['pcc'] = df['pcc'].fillna(df['pcc'].mode()[0])\n", "df['ba'] = df['ba'].fillna(df['ba'].mode()[0])\n", "df['bgr'] = df['bgr'].fillna(df['bgr'].median())\n", "df['bu'] = df['bu'].fillna(df['bu'].median())\n", "df['sc'] = df['sc'].fillna(df['sc'].median())\n", "df['sod'] = df['sod'].fillna(df['sod'].median())\n", "df['pot'] = df['pot'].fillna(df['pot'].median())\n", "df['hemo'] = df['hemo'].fillna(df['hemo'].median())\n", "df['pcv'] = df['pcv'].fillna(df['pcv'].median())\n", "df['wc'] = df['wc'].fillna(df['wc'].median())\n", "df['rc'] = df['rc'].fillna(df['rc'].median())\n", "df['htn'] = df['htn'].fillna(df['htn'].mode()[0])\n", "df['dm'] = df['dm'].fillna(df['dm'].mode()[0])\n", "df['cad'] = df['cad'].fillna(df['cad'].mode()[0])\n", "df['appet'] = df['appet'].fillna(df['appet'].mode()[0])\n", "df['pe'] = df['pe'].fillna(df['pe'].mode()[0])\n", "df['ane'] = df['ane'].fillna(df['ane'].mode()[0])"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Converting Non - Numerical to Numerical <br>\n", "# Since All Non - Numerical Variables are Nominal we can perform One Hot Encoding"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Getting all the Non - Numerical variables to one dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categorical_variables = df[['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Dummy_variables = pd.get_dummies(categorical_variables)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Numerical_variables = df[['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Data = pd.concat([Numerical_variables, Dummy_variables], axis = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Data Preprocessing Step is Completed "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Performing PCA - Dimension Reduction without Scaling"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.decomposition import PCA"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca = PCA()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_values_without_Scaling = pca.fit_transform(Data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["columns = list(range(1,39))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_df_without_Scaling = pd.DataFrame(pca_values_without_Scaling, columns = columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_ratio_without_Scaling = pca.explained_variance_ratio_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_without_Scaling = np.cumsum(np.round(var_ratio_without_Scaling, decimals = 4)*100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_df_without_Scaling = pd.DataFrame(var_without_Scaling)\n", "var_df_without_Scaling = np.transpose(var_df_without_Scaling)\n", "var_df_without_Scaling = pd.DataFrame(var_df_without_Scaling, columns = columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_df_without_Scaling = pca_df_without_Scaling.append(var_df_without_Scaling, ignore_index = True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_df_without_Scaling.rename({400: 'Variance'}, axis = 'index', inplace = True) ## The PCA Without Scaling doesnot seems right"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Performing PCA With Scaling"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import scale"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_norm = pd.DataFrame(scale(Data))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["desc_norm = data_norm.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_values_with_Scaling = pca.fit_transform(data_norm)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_df_with_Scaling = pd.DataFrame(pca_values_with_Scaling, columns = columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_ratio_with_Scaling = pca.explained_variance_ratio_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_with_Scaling = np.cumsum(np.round(var_ratio_with_Scaling, decimals = 4)*100)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_df_with_Scaling = pd.DataFrame(var_with_Scaling)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_df_with_Scaling = np.transpose(var_df_with_Scaling)\n", "var_df_with_Scaling = pd.DataFrame(var_df_with_Scaling, columns = columns)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_df_with_Scaling = pca_df_with_Scaling.append(var_df_with_Scaling, ignore_index = True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pca_df_with_Scaling.rename({400: 'Variance'}, axis = 'index', inplace = True) ## The PCA Without Scaling  seems right"]}, {"cell_type": "markdown", "metadata": {}, "source": ["By taking 18 PCA values we can extract 90% of Data from 38 Features<br>\n", "Seems like PCA should be happened for Scaled data only and By then only it will be Successfull"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}